{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to point source imaging with cosipy-classic\n",
    "In this notebook, we'll use a Richardson-Lucy deconvolution algorithm to image four point sources: the Crab, Cyg X-1, Cen A, and Vela. This analysis requires significant computer memory (>50 GB), so you may want to use a more resource-intensive computer for this work. Please refer to the README for additional information on each step of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "We will need to import the cosipy-classic functions from COSIpy_dc1.py, response_dc1, and COSIpy_tools_dc1, as well as some other standard Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from COSIpy_dc1 import *\n",
    "import response_dc1\n",
    "from COSIpy_tools_dc1 import *\n",
    "\n",
    "import pickle\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define file names\n",
    "The 'Point_sources_10x_BG.tra.gz' file contains simulations of all four point sources, each at 10X their true flux, and Ling background. This is our data file.\n",
    "\n",
    "You can optionally image only the point sources (without background) by changing this file to point source-only simulation. You will have to adjust the RL algorithm parameters later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data_products' # directory containing data & response files\n",
    "filename = 'Point_sources_10x_BG.tra.gz' # combined simulation\n",
    "response_filename = data_dir + '/Continuum_imaging_response.npz' # detector response\n",
    "background_filename = data_dir + '/Scaled_Ling_BG_1x.npz' # background response\n",
    "background_mode = 'from file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read simulation and define analysis object\n",
    "Read in the data set and create the main cosipy-classic “analysis1\" object, which provides various functionalities to study the specified file. This cell usually takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1 = COSIpy(data_dir, filename)\n",
    "analysis1.read_COSI_DataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin the data\n",
    "Calling \"get_binned_data()\" may take several minutes, depending on the size of the dataset and the number of bins. Keep an eye on memory here: if your time bins are very small, for example, this could be an expensive operation.\n",
    "\n",
    "As currently written, \"get_binned_data()\" uses about **16 GB memory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the bin sizes\n",
    "Delta_T = 1800 # time bin size in seconds\n",
    "energy_bin_edges = np.array([150, 220, 325, 480, 520, 765, 1120, 1650, 2350, 3450, 5000]) # as defined in the response\n",
    "pixel_size = 6. # as defined in the respoonse\n",
    "\n",
    "analysis1.dataset.time_binning_tags(time_bin_size=Delta_T) # time binning\n",
    "analysis1.dataset.init_binning(energy_bin_edges=energy_bin_edges, pixel_size=pixel_size) # energy and pixel binning\n",
    "analysis1.dataset.get_binned_data() # bin data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the shape of the binned data.\n",
    "The binned data are contained in \"analysis1.dataset.binned_data.\" This is a 4-dimensional object representing the 5 dimensions of the Compton data space: (time, energy, $\\phi$, FISBEL).\n",
    "\n",
    "The number of bins in each dimension are shown by calling \"shape.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"time, energy, phi, fisbel\")\n",
    "print(analysis1.dataset.binned_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can print the number of time bins, the width of each time bin, and the total time\n",
    "print(analysis1.dataset.times.n_time_bins)\n",
    "print(analysis1.dataset.times.times_wid)\n",
    "print(analysis1.dataset.times.total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot raw spectrum & light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis1.dataset.plot_raw_spectrum()\n",
    "plt.xscale('log')\n",
    "\n",
    "analysis1.dataset.plot_lightcurve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the pointing object with the cosipy pointing class.\n",
    "This may also take several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of poitings (balloon stability + Earth rotation)\n",
    "pointing1 = Pointing(dataset=analysis1.dataset,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the path of the Crab through the field-of-view.\n",
    "This isn't necessary for the imaging algorithm, but is illustrative in the case of a point source. Take the Crab as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_crab, b_crab = 184.55746, -5.78436 # Location of the Crab in Galactic coordinates [deg]\n",
    "\n",
    "source = 'Crab Nebula'\n",
    "\n",
    "plt.plot(pointing1.zpoins[:,0]+360, pointing1.zpoins[:,1], 'ko', label='COSI zenith pointing')\n",
    "plt.plot(l_crab, b_crab, '*r', markersize=10 , label=f'{source}')\n",
    "plt.xlabel('Longitude [deg]')\n",
    "plt.ylabel('Latitude [deg]')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# COSI's field of view extends ~60 deg from zenith, hence why the Zenith is labeled as +60 deg above the horizon\n",
    "analysis1.plot_elevation([l_crab], [b_crab], [f'{source}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the BG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ling BG simulation to model atmospheric background\n",
    "background1 = BG(dataset=analysis1.dataset,mode=background_mode,filename=background_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the Response Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# continuum response\n",
    "rsp = response_dc1.SkyResponse(filename=response_filename,pixel_size=pixel_size) # read in detector response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the shape of the data space\n",
    "The shape of the response spans (Galactic latitude $b$, Galactic longitude $\\ell$, Compton scattering angle $\\phi$,  FISBEL, energy).The shape of the data and background objects span (time, energy, Compton scattering angle, FISBEL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsp.rsp.response_grid_normed_efinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(analysis1.dataset.binned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(background1.bg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imaging Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a grid on the sky to make images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenient variable for deg --> radian conversion\n",
    "deg2rad = np.pi/180.\n",
    "\n",
    "# We define our sky-grid on a regular (pixel_size x pixel_size) grid for testing (later finer grid)\n",
    "binsize = pixel_size\n",
    "\n",
    "# Galactic coordiantes: l and b pixel edges\n",
    "l_arrg = np.linspace(-180, 180, int(360/binsize)+1)\n",
    "b_arrg = np.linspace(-90, 90, int(180/binsize)+1)\n",
    "\n",
    "# Number of pixels in l and b\n",
    "n_l = int(360/binsize)\n",
    "n_b = int(180/binsize)\n",
    "\n",
    "# Making a grid\n",
    "L_ARRg, B_ARRg = np.meshgrid(l_arrg, b_arrg)\n",
    "\n",
    "# Choosing the centre points as representative\n",
    "l_arr = l_arrg[0:-1] + binsize/2\n",
    "b_arr = b_arrg[0:-1] + binsize/2\n",
    "L_ARR, B_ARR = np.meshgrid(l_arr, b_arr)\n",
    "\n",
    "# Define solid angle for each pixel for normalisations later\n",
    "domega = (binsize*deg2rad)*(np.sin(np.deg2rad(B_ARR + binsize/2)) - np.sin(np.deg2rad(B_ARR - binsize/2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert sky grid to zenith/azimuth pairs for all pointings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the zeniths and azimuths on that grid for all times\n",
    "zensgrid,azisgrid = zenaziGrid(pointing1.ypoins[:,0], pointing1.ypoins[:,1],\n",
    "                               pointing1.xpoins[:,0], pointing1.xpoins[:,1],\n",
    "                               pointing1.zpoins[:,0], pointing1.zpoins[:,1],\n",
    "                               L_ARR.ravel(), B_ARR.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for next routines ... \n",
    "zensgrid = zensgrid.reshape(n_b, n_l, len(pointing1.xpoins))\n",
    "azisgrid = azisgrid.reshape(n_b, n_l, len(pointing1.xpoins))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get observation indices for non-zero bins\n",
    "Here we also chose an energy bin to image. Energy bin \"2\" in the continuum response (and, necessarily, \"energy_bin_edges\" at the beginning of the notebook) is $320-480$ keV. We choose this energy bin because it has the highest count rate. Refer to the energy spectrum generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebin = 2 # Analyzing 320-480 keV \n",
    "nonzero_idx = background1.calc_this[ebin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the response dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_response_CDS = rsp.rsp.response_grid_normed_efinal.reshape(\n",
    "    n_b,\n",
    "    n_l,\n",
    "    analysis1.dataset.phis.n_phi_bins*\\\n",
    "    analysis1.dataset.fisbels.n_fisbel_bins, analysis1.dataset.energies.n_energy_bins)[:, :, nonzero_idx, ebin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced response dimensions:\n",
    "# lat x lon x CDS\n",
    "sky_response_CDS.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get the response of an image for arbitrary time binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_response_from_pixelhit_general(Response,zenith,azimuth,dt,n_hours,binsize=6,cut=60,altitude_correction=False,al=None):\n",
    "    \"\"\"\n",
    "    Get Compton response from hit pixel for each zenith/azimuth vector(!) input.\n",
    "    Binsize determines regular(!!!) sky coordinate grid in degrees.\n",
    "\n",
    "    :param: zenith        Zenith positions of all points of predefined sky grid with\n",
    "                          respect to the instrument (in deg)\n",
    "    :param: azimuth       Azimuth positions of all points of predefined sky grid with\n",
    "                          respect to the instrument (in deg)\n",
    "    :option: binsize      Default 5 deg (matching the sky dimension of the response). If set\n",
    "                          differently, make sure it matches the sky dimension as otherwise,\n",
    "                          false results may be returned\n",
    "    :option: cut          Threshold to cut the response calculation after a certain zenith angle.\n",
    "                          Default 60\n",
    "    :param: n_hours       Number of hours in cdxervation\n",
    "    :option: altitude_correction Default False: use interpolated transmission probability, normalised to 33 km and 500 keV,\n",
    "                          to modify number of expected photons as a function of altitude and zenith angle of cdxervation\n",
    "    :option: al           Altitude values according to dt from construct_pointings(); used of altitude_correction is set to True\n",
    "    \"\"\"\n",
    "\n",
    "    # assuming useful input:\n",
    "    # azimuthal angle is periodic in the range [0,360[\n",
    "    # zenith ranges from [0,180[\n",
    "\n",
    "    # check which pixel (index) was hit on regular grid\n",
    "    hit_pixel_zi = np.floor(zenith/binsize)\n",
    "    hit_pixel_ai = np.floor(azimuth/binsize)\n",
    "\n",
    "    # and which pixel centre\n",
    "    hit_pixel_z = (hit_pixel_zi+0.5)*binsize\n",
    "    hit_pixel_a = (hit_pixel_ai+0.5)*binsize\n",
    "\n",
    "    # check which zeniths are beyond threshold\n",
    "    bad_idx = np.where(hit_pixel_z > cut)\n",
    "\n",
    "    # set hit pixels to output array\n",
    "    za_idx = np.array([hit_pixel_zi,hit_pixel_ai]).astype(int)\n",
    "\n",
    "    nz = zenith.shape[2]\n",
    "\n",
    "    n_lon = int(360/binsize)\n",
    "    n_lat = int(180/binsize)\n",
    "    \n",
    "    l_arrg = np.linspace(-180,180,int(360/binsize)+1)\n",
    "    b_arrg = np.linspace(-90,90,int(180/binsize)+1)\n",
    "    L_ARRg, B_ARRg = np.meshgrid(l_arrg,b_arrg)\n",
    "    l_arr = l_arrg[0:-1]+binsize/2\n",
    "    b_arr = b_arrg[0:-1]+binsize/2\n",
    "    L_ARR, B_ARR = np.meshgrid(l_arr,b_arr)\n",
    "\n",
    "    # take care of regular grid by applying weighting with latitude\n",
    "    weights = ((binsize*np.pi/180)*(np.sin(np.deg2rad(B_ARR+binsize/2)) - np.sin(np.deg2rad(B_ARR-binsize/2)))).repeat(nz).reshape(n_lat,n_lon,nz)\n",
    "    weights[bad_idx] = 0\n",
    "\n",
    "    \n",
    "    # check for negative weights and indices and remove\n",
    "    weights[za_idx[0,:] < 0] = 0.\n",
    "    weights[za_idx[1,:] < 0] = 0.\n",
    "    za_idx[0,za_idx[0,:] < 0] = 0.\n",
    "    za_idx[1,za_idx[1,:] < 0] = 0.\n",
    "        \n",
    "    \n",
    "    if altitude_correction == True:\n",
    "        altitude_response = return_altitude_response()\n",
    "    else:\n",
    "        altitude_response = one_func\n",
    "\n",
    "    # get responses at pixels    \n",
    "    image_response = np.zeros((n_hours,n_lat,n_lon,Response.shape[2]))\n",
    "\n",
    "    for c in tqdm(range(n_hours)):\n",
    "        cdx = np.where((pointing1.cdtpoins > analysis1.dataset.times.times_min[analysis1.dataset.times.n_ph_dx[c]]) &\n",
    "                       (pointing1.cdtpoins <= analysis1.dataset.times.times_max[analysis1.dataset.times.n_ph_dx[c]]))[0]\n",
    "    \n",
    "        # this calculation is basically a look-up of the response entries. In general, weighting (integration) with the true shape can be introduced, however with a lot more computation time (Simpson's rule in 2D ...)\n",
    "        image_response[c,:,:,:] += np.sum(Response[za_idx[0,:,:,cdx],za_idx[1,:,:,cdx],:]*np.einsum('klij->iklj', weights[:,:,cdx,None])*dt[cdx,None,None,None],axis=0)#*altitude_weights[:,:,None]\n",
    "        \n",
    "    return image_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the general response for the current data set\n",
    "This has to be done only once (for the data set).\n",
    "\n",
    "Takes ~20 minutes to run and ~94 GB memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 90 # This mirrors the earth horizon cut in the response\n",
    "sky_response_scaled = get_image_response_from_pixelhit_general(\n",
    "    Response=sky_response_CDS,\n",
    "    zenith=zensgrid,\n",
    "    azimuth=azisgrid,\n",
    "    dt=pointing1.dtpoins,\n",
    "    n_hours=analysis1.dataset.times.n_ph,\n",
    "    binsize=pixel_size,\n",
    "    cut=cut,\n",
    "    altitude_correction=False,\n",
    "    al=np.ones(len(pointing1.dtpoins)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-set-specific response dimensions\n",
    "# times x lat x lon x CDS\n",
    "sky_response_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exposure map\n",
    "i.e. the response weighted by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expo_map = np.zeros((n_b, n_l))\n",
    "\n",
    "for i in tqdm(range(sky_response_scaled.shape[0])):\n",
    "    expo_map += np.sum(sky_response_scaled[i,:,:,:], axis=2)\n",
    "    \n",
    "print(f'expo_map shape: {expo_map.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the exposure map weighted with the pixel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(projection='aitoff')\n",
    "p = plt.pcolormesh(L_ARRg*deg2rad,B_ARRg*deg2rad,np.roll(expo_map/domega,axis=1,shift=0))\n",
    "plt.contour(L_ARR*deg2rad,B_ARR*deg2rad,np.roll(expo_map/domega,axis=1,shift=0),colors='black')\n",
    "plt.colorbar(p, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the RL algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define regions of the sky that we actually cannot see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we select everything, i.e. we have no bad exposure\n",
    "\n",
    "bad_expo = np.where(expo_map/domega <= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function for a starting map for the RL deconvolution. We choose an isotropic map, i.e. all pixels on the sky are initialized with the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IsoMap(ll,bb,A0,binsize=pixel_size):\n",
    "    shape = np.ones(ll.shape)\n",
    "    norm = np.sum(shape*(binsize*np.pi/180)*(np.sin(np.deg2rad(bb+binsize/2)) - np.sin(np.deg2rad(bb-binsize/2))))\n",
    "    val = A0*shape/norm\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of time bins (should be the first dimension of the response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2h =  analysis1.dataset.times.n_time_bins\n",
    "d2h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only one energy bin (as above) for data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ebin: ',ebin)\n",
    "dataset = analysis1.dataset.binned_data[:,ebin,:,:].reshape(d2h,\n",
    "                                                            analysis1.dataset.phis.n_phi_bins*analysis1.dataset.fisbels.n_fisbel_bins)[:,nonzero_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same for background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_model = background1.bg_model_reduced[ebin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for consistency of data and background\n",
    "They must have the same dimensions. If not, the algorithm won't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape,background_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define background model cuts, indices, and resulting number of cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_cuts, idx_arr, Ncuts = background1.bg_cuts, background1.idx_arr, background1.Ncuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the modified RL algorithm implemented here, we need to load a stan model that fits background plus two images (the current image plus a delta image given by the RL formalism)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    #read stanmodel.pkl (if already compiled)\n",
    "    model_multimap = pickle.load(open('stanmodel.pkl', 'rb'))\n",
    "\n",
    "except:\n",
    "    print('Model not yet compiled, doing that now (might take a while).')\n",
    "    \n",
    "    # compile model (if not yet compiled):\n",
    "    model_multimap = pystan.StanModel('stanmodel.stan')\n",
    "\n",
    "    with open(data_dir + 'stanmodel.pkl', 'wb') as f:\n",
    "        pickle.dump(model_multimap, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an initial guess for the background amplitude\n",
    "Feel free to play with this value, but here are suggestions informed by testing thus far:\n",
    "\n",
    "### If source+BG:\n",
    "We suggest setting \"fitted_bg\" to 0.9 or 0.99 when the loaded data/simulation (analysis1 object) contains both source and background. This is a rough estimate of the background contribution (90, 99%) to the entire data set.\n",
    "\n",
    "### If analyzing source only:\n",
    "When the analysis1 object does not contain background, we suggest setting this parameter to 1E-6, i.e. very close to zero background contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_bg = np.array([0.9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richardson-Lucy algorithm\n",
    "\n",
    "## Individual steps are explained in code.\n",
    "The steps follow the algorithm as outlined in [Knödlseder et al. 1999](https://ui.adsabs.harvard.edu/abs/1999A%26A...345..813K/abstract). Refer to that paper for a mathematical description of the algorithm.\n",
    "\n",
    "The total memory used during these iterations is about 94 GB!! You might not be able to do much else with your machine while this is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might not use this depending on if you choose to smooth the delta map\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with these variables!\n",
    "#############################\n",
    "# initial map (isotropic flat, small value)\n",
    "map_init = IsoMap(L_ARR, B_ARR, 0.01)\n",
    "\n",
    "# number of RL iterations, Usually test with ~150 iterations. \n",
    "iterations = 150 \n",
    "\n",
    "# acceleration parameter\n",
    "afl_scl = 2000.\n",
    "#############################\n",
    "\n",
    "\n",
    "## Define background (to be sure it's the same as before)\n",
    "bg_cuts, idx_arr, Ncuts = background1.bg_cuts, background1.idx_arr, background1.Ncuts\n",
    " \n",
    "    \n",
    "## Save intermediate iterations: initialise arrays to save images and other parameters\n",
    "# maps per iteration\n",
    "map_iterations = np.zeros((n_b, n_l, iterations))\n",
    "\n",
    "# likelihood of maps (vs. initial i.e. basically only background)\n",
    "map_likelihoods = np.zeros(iterations)\n",
    "\n",
    "# fit likelihoods, ie fit quality\n",
    "intermediate_lp = np.zeros(iterations)\n",
    "\n",
    "# acceleration parameters (lambda)\n",
    "acc_par = np.zeros(iterations)\n",
    "\n",
    "# fitted background parameters \n",
    "bg_pars = np.zeros((iterations,Ncuts))\n",
    "\n",
    "\n",
    "## Zeroth iteration: copy initial map to become the 'old map' (see below)\n",
    "map_old = map_init\n",
    "\n",
    "# cf. Knoedlseder+1997 what the values denominator etc are\n",
    "# this is the response R summed over the CDS and the time bins\n",
    "denominator = expo_map\n",
    "\n",
    "# zeroth iteration is then just the initial map\n",
    "map_iterations[:,:,0] = map_old#[]\n",
    "\n",
    "# convolve this map with the response\n",
    "expectation_init = 0\n",
    "print('Convolving with response (init expectation), iteration 0')\n",
    "for i in tqdm(range(n_b)):\n",
    "    for j in range(n_l):\n",
    "        expectation_init += sky_response_scaled[:,i,j,:]*map_init[i,j]\n",
    "\n",
    "# set old expectation (in data space bins) to new expectation (convolved image)\n",
    "expectation_old = expectation_init\n",
    "\n",
    "### now we have the expectation of the image. Need to go to the BG \n",
    "        \n",
    "###########################################################\n",
    "###########################################################\n",
    "## here run over the number of iterations #################\n",
    "###########################################################\n",
    "## the time for the convolutions is very large ############\n",
    "## this can be 10 minutes (!) per iteration ###############\n",
    "## this should be tested for a few iterations #############\n",
    "## and then run overnight or similar ######################\n",
    "###########################################################\n",
    "###########################################################\n",
    "for its in tqdm(range(1,iterations)):\n",
    "    \n",
    "    # setting the map to zero where we selected a bad exposure (we didn't, but to keep it general)\n",
    "    map_old[bad_expo[0],bad_expo[1]] = 0\n",
    "    \n",
    "    # check for each pixel to be finite\n",
    "    map_old[np.where(np.isnan(map_old) == True)] = 0\n",
    "    \n",
    "    # make new background for the next iteration\n",
    "    bg_cuts, idx_arr, Ncuts = background1.bg_cuts, background1.idx_arr, background1.Ncuts\n",
    "    \n",
    "    # temporary background model\n",
    "    tmp_model_bg = np.zeros((d2h,background1.bg_model_reduced[ebin].shape[1]))\n",
    "    \n",
    "    # there could be something different for the first iteration (here it isn't, same function call)\n",
    "    if its == 1:\n",
    "        for g in range(d2h):\n",
    "            tmp_model_bg[g,:] = background_model[g,:]*fitted_bg[idx_arr-1][g]\n",
    "    else:\n",
    "        for g in range(d2h):\n",
    "            tmp_model_bg[g,:] = background_model[g,:]*fitted_bg[idx_arr-1][g]\n",
    "            \n",
    "    # expectation (in data space) is the image (expectation_old) plus the background (tmp_model_bg)\n",
    "    expectation_tot_old = expectation_old + tmp_model_bg \n",
    "\n",
    "    # calculate likelihood of currect total expectation\n",
    "    map_likelihoods[its-1] = cashstat(dataset.ravel(),expectation_tot_old.ravel())\n",
    "    \n",
    "    # calculate numerator of RL algorithm\n",
    "    numerator = 0\n",
    "    print('Calculating Delta image, iteration '+str(its)+', numerator')\n",
    "    for i in tqdm(range(d2h)):\n",
    "        for j in range(dataset.shape[1]):\n",
    "            numerator += (dataset[i,j]/expectation_tot_old[i,j]-1)*sky_response_scaled[i,:,:,j]\n",
    "    \n",
    "    # calculate delta map (denominator scaled by fourth root to avoid exposure edge effects)\n",
    "    # You can try changing 0.25 to 0, 0.5, for example\n",
    "    delta_map_tot_old = (numerator/denominator)*map_old*(denominator)**0.25\n",
    "    \n",
    "    # Alternatively, you can also try to smooth it \n",
    "    #delta_map_tot_old = gaussian_filter(delta_map_tot_old, 0.5)\n",
    "    \n",
    "    #################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    # check again for finite values and zero our bad exposure regions\n",
    "    nan_idx = np.where(np.isnan(delta_map_tot_old) == 1)\n",
    "    delta_map_tot_old[nan_idx[0],nan_idx[1]] = 0\n",
    "    delta_map_tot_old[bad_expo[0],bad_expo[1]] = 0\n",
    "\n",
    "    # plot each iterations and its delta map \n",
    "    # (not required, but nice to see how the algorithm is doing)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.subplot(121)\n",
    "    plt.pcolormesh(L_ARRg,B_ARRg,np.roll(map_old, axis=1, shift=0)) \n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.pcolormesh(L_ARRg,B_ARRg,np.roll(delta_map_tot_old, axis=1, shift=0)) \n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    # convolve delta image\n",
    "    print('Convolving Delta image, iteration '+str(its))\n",
    "    conv_delta_map_tot = 0\n",
    "    for i in tqdm(range(n_b)):\n",
    "        for j in range(n_l):\n",
    "            conv_delta_map_tot += sky_response_scaled[:,i,j,:]*delta_map_tot_old[i,j]\n",
    "    \n",
    "    # find maximum acceleration parameter to multiply delta image with\n",
    "    # so that the total image is still positive everywhere\n",
    "    print('Finding maximum acceleration parameter, iteration '+str(its))\n",
    "    try:\n",
    "        len_arr = []\n",
    "        for i in range(0,10000):\n",
    "            len_arr.append(len(np.where((map_old+delta_map_tot_old*i/afl_scl) < 0)[0]))\n",
    "        len_arr = np.array(len_arr)\n",
    "        afl = np.max(np.where(len_arr == 0)[0])\n",
    "        print('Maximum acceleration parameter found: ',afl/afl_scl)\n",
    "\n",
    "        \n",
    "        # fit delta map and current map to speed up RL algorithm\n",
    "        print('Fitting delta-map in addition to old map, iteration '+str(its))\n",
    "        # dictionary for data set and prior\n",
    "        # note that here the value for N should be your response CDS dimension\n",
    "        # should be last dimension of the scaled response thing (change to your value)\n",
    "        data_multimap = dict(N = dataset.shape[1],\n",
    "                     Nh = d2h,\n",
    "                     Ncuts = Ncuts,\n",
    "                     Nsky = 2,\n",
    "                     acceleration_factor_limit=afl*0.95,\n",
    "                     bg_cuts = bg_cuts,\n",
    "                     bg_idx_arr = idx_arr,\n",
    "                     y = dataset.ravel().astype(int),\n",
    "                     bg_model = tmp_model_bg,\n",
    "                     conv_sky = np.concatenate([[expectation_old],[conv_delta_map_tot/afl_scl]]),\n",
    "                     mu_flux = np.array([1,afl/2]),\n",
    "                     sigma_flux = np.array([1e-2,afl]),\n",
    "                     mu_Abg = fitted_bg,    # can play with this\n",
    "                     sigma_Abg = fitted_bg) # can play with this\n",
    "\n",
    "        # fit;\n",
    "        # initial values for fit (somewhat sensitive here with COSI data)\n",
    "        init = {}\n",
    "        init['flux'] = np.array([1.,afl/2.])\n",
    "        init['Abg'] = np.repeat(fitted_bg, Ncuts) # can play with this\n",
    "        \n",
    "        # fit: might take some time but it shouldn't be more than a minute\n",
    "        op2D = model_multimap.optimizing(data=data_multimap,init=init,as_vector=False,verbose=True,\n",
    "                                                tol_rel_grad=1e3,tol_obj=1e-20)\n",
    "\n",
    "        # save values\n",
    "        print('Saving new map, and fitted parameters, iteration '+str(its))\n",
    "        intermediate_lp[its-1] = op2D['value']\n",
    "        acc_par[its-1] = op2D['par']['flux'][1]\n",
    "        bg_pars[its-1,:] = op2D['par']['Abg']\n",
    "  \n",
    "        # make new map as old map plus scaled delta map\n",
    "        map_new = map_old+op2D['par']['flux'][1]*delta_map_tot_old/afl_scl\n",
    "    \n",
    "        # same with expectation (data space)\n",
    "        expectation_new = expectation_old + op2D['par']['flux'][1]*conv_delta_map_tot/afl_scl\n",
    "        \n",
    "\n",
    "    except:\n",
    "        # if the fit failed...\n",
    "        # this shouldn't happen too often (or at all)\n",
    "        print('############## Fit failed! proceeding without acceleration ##############')\n",
    "        map_new = map_old + delta_map_tot_old\n",
    "        expectation_new = expectation_old + conv_delta_map_tot\n",
    "    \n",
    "    # check finite values again\n",
    "    if its == 1:\n",
    "        bad_index_init = np.where(np.isnan(map_new) == True)\n",
    "    \n",
    "    # also here\n",
    "    map_new[bad_expo[0],bad_expo[1]] = 0\n",
    "    map_new[np.where(np.isnan(map_new) == True)] = 0\n",
    "    map_iterations[:,:,its] = map_new\n",
    "\n",
    "    # swap maps\n",
    "    map_old = map_new\n",
    "    \n",
    "    # and expectations\n",
    "    expectation_old = expectation_new\n",
    "    \n",
    "    # and repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the fitted background parameter and the map flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(its), [i[0] for i in bg_pars[:its]], '.-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('BG params]')\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "map_fluxes = np.zeros(its)\n",
    "for i in range(its):\n",
    "    map_fluxes[i] = np.sum(map_iterations[:,:,i]*domega)\n",
    "    \n",
    "plt.plot(map_fluxes[:its],'o-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Flux')# [ph/keV]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did the algorithm converge? Look at the likelihoods.\n",
    "intermediate_lp: Fit likelihoods, i.e. fit quality\n",
    "\n",
    "map_likelihoods: likelihood of maps (vs. initial i.e. basically only background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(range(its+1)[:-1], intermediate_lp[:its+1][:-1], '.-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('likelihood (intermediate_lp)')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(range(its+1)[:-1], map_likelihoods[:its+1][:-1], '.-')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('likelihood (map_likelihoods)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the image!\n",
    "You can loop over all iterations to make a GIF or just show one iteration (usually the final iteration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import Video\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from matplotlib import animation\n",
    "\n",
    "from matplotlib import colors\n",
    "\n",
    "from scipy.ndimage import gaussian_filter as smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image to plot\n",
    "idx = its - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a color map like viridis (matplotlib default), nipy_spectral, twilight_shifted, etc. Not jet.\n",
    "cmap = plt.get_cmap('viridis') \n",
    "\n",
    "# Bad exposures will be gray\n",
    "cmap.set_bad('lightgray')\n",
    "\n",
    "\n",
    "##################\n",
    "# Select here which pixels should be gray\n",
    "map_iterations_nan = np.copy(map_iterations)\n",
    "\n",
    "# Select also non-zero exposures here to be gray (avoiding the edge effects)\n",
    "# You can play with this. Most success in testing with 1e4, 1e3\n",
    "bad_expo = np.where(expo_map/domega <= 1e4) \n",
    "\n",
    "for i in range(iterations):\n",
    "    map_iterations_nan[bad_expo[0], bad_expo[1], i] = np.nan\n",
    "#################    \n",
    "\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(10.24,7.68), subplot_kw={'projection':'aitoff'}, nrows=1, ncols=1)\n",
    "\n",
    "ax.set_xticks(np.array([-120,-60,0,60,120])*deg2rad)\n",
    "ax.set_xticklabels([r'$-120^{\\circ}$'+'\\n',\n",
    "                            r'$-60^{\\circ}$'+'\\n',\n",
    "                            r'$0^{\\circ}$'+'\\n',\n",
    "                            r'$60^{\\circ}$'+'\\n',\n",
    "                            r'$120^{\\circ}$'+'\\n'])\n",
    "ax.tick_params(axis='x', colors='orange')\n",
    "\n",
    "ax.set_yticks(np.array([-60,-30,0,30,60])*deg2rad)\n",
    "ax.tick_params(axis='y', colors='orange')\n",
    "\n",
    "plt.xlabel('Gal. Lon. [deg]')\n",
    "plt.ylabel('Gal. Lat. [deg]')\n",
    "\n",
    "\n",
    "\n",
    "# \"ims\" is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "\n",
    "\n",
    "# If you want to make a GIF of all iterations:\n",
    "#for i in range(iterations):\n",
    "\n",
    "# If you only want to plot one image:\n",
    "for i in [idx]:\n",
    "\n",
    "    ttl = plt.text(0.5, 1.01, f'RL iteration {i}', horizontalalignment='center', \n",
    "                   verticalalignment='bottom', transform=ax.transAxes)\n",
    "    \n",
    "    # Either gray-out bad exposure (map_iterations_nan) or don't mask (map_iterations)\n",
    "    # Masking out bad exposure \n",
    "    image = map_iterations_nan[:, :, i]\n",
    "    #image = map_iterations[:, :, i]\n",
    "\n",
    "    \n",
    "    img = ax.pcolormesh(L_ARRg*deg2rad,B_ARRg*deg2rad,\n",
    "                        \n",
    "                        # Can shift the image along longitude. Here, no shift.\n",
    "                        np.roll(image, axis=1, shift=0),\n",
    "            \n",
    "                        # Optionally smooth with gaussian filter\n",
    "                        #smooth(np.roll(image, axis=1, shift=0), 0.75/pixel_size),\n",
    "                        \n",
    "                        cmap=plt.cm.viridis,\n",
    "                        \n",
    "                        # Optionally set the color scale. Default: linear\n",
    "                        #norm=colors.PowerNorm(0.33)\n",
    "                       )\n",
    "    ax.grid()\n",
    "    \n",
    "    ims.append([img, ttl])\n",
    "\n",
    "cbar = fig.colorbar(img, orientation='horizontal')\n",
    "#cbar.ax.set_xlabel(r'Flux [10$^{-2}$ ph cm$^{-2}$ s$^{-1}$]')\n",
    "    \n",
    "\n",
    "# Can save a sole image as a PDF \n",
    "#plt.savefig(data_dir + f'images/point_sources_RL_image_iteration{idx}.pdf', bbox_inches='tight')\n",
    "    \n",
    "    \n",
    "# # Can save all iterations as a GIF\n",
    "# ani = animation.ArtistAnimation(fig, ims, interval=200, blit=True, repeat_delay=0)\n",
    "# ani.save(f'/home/jacqueline/point_sources_RL_image_{idx}iterations.gif')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What do we see?\n",
    "The Crab nebula is the only easily visible source in this combined simulation of 10x flux Crab, 10x flux Cygnus X-1, 10x flux Centaurus A, 10x Vela, and 1x flux Ling background (scaled to the observed 2016 flight background level). \n",
    "\n",
    "You can play with the color scaling to try to enhance the appearance of the other sources. Vela is likely too dim to be seen, however. \n",
    "\n",
    "You can also try running this notebook without including the Ling background. Change the loaded .tra.gz file at the beginning, adjust RL parameters as necessary, and see if the four point sources are more easily resolved without background contamination!\n",
    "\n",
    "As another suggestion, what happens if you run this notebook using the 511 keV response? The 1809 keV response? A different energy bin of the continuum response? \n",
    "\n",
    "You can try combining these four point sources and Ling BG with the 10x 511 keV and 10x $^{26}$Al simulations for a full combined imaging test, using all three response simulations too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (beta) Study the fluxes in individual pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_flux(image, l, b, num_neighbors=1):\n",
    "    '''\n",
    "    Find the flux at a given (l, b) coordinate of interest in the final image.\n",
    "    Also find the flux in the neighboring pixels.\n",
    "    \n",
    "    Parameters:\n",
    "    image: required, final image to study, array\n",
    "    l: required, Galactic longitude of interest [deg], float\n",
    "    b: required, Galactic latitude of interest [deg], float\n",
    "    num_neighbors: optional, number of neighboring pixels in each direction.\n",
    "                   default: 1, i.e. 1 pixels on either side of the pixel of \n",
    "                            interest for a total of 8 neighboring pixels\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary of pixel boundaries and the flux contained therein. \n",
    "    Primary pixel of interest is listed first, followed by neighboring pixels.\n",
    "    '''\n",
    "    \n",
    "    final_image = image*domega\n",
    "    \n",
    "    print('Total flux in whole image:', np.sum(final_image), '\\n')\n",
    "    \n",
    "    for i in range(1, len(l_arrg)):\n",
    "        l0 = l_arrg[i-1]\n",
    "        l1 = l_arrg[i]\n",
    "\n",
    "        for j in range(1, len(b_arrg)):\n",
    "            b0 = b_arrg[j-1]\n",
    "            b1 = b_arrg[j]\n",
    "\n",
    "            if (l0 < l <= l1) and (b0 < b <= b1):\n",
    "\n",
    "                pixels = {}\n",
    "                \n",
    "                pixels[f'l: ({l0}, {l1}), b: ({b0}, {b1})'] = final_image[j-1, i-1]\n",
    "                \n",
    "                for n in range(1, num_neighbors+1):\n",
    "                    \n",
    "                    # move up n\n",
    "                    pixels[f'l: ({l_arrg[i-1]}, {l_arrg[i]}), b: ({b_arrg[j-1+n]}, {b_arrg[j+n]})'] = final_image[j-1+n, i-1]\n",
    "                    \n",
    "                    # move down n\n",
    "                    pixels[f'l: ({l_arrg[i-1]}, {l_arrg[i]}), b: ({b_arrg[j-1-n]}, {b_arrg[j-n]})'] = final_image[j-1-n, i-1]\n",
    "                    \n",
    "                    # move right n\n",
    "                    pixels[f'l: ({l_arrg[i-1+n]}, {l_arrg[i+n]}), b: ({b_arrg[j-1]}, {b_arrg[j]})'] = final_image[j-1, i-1+n]\n",
    "                    \n",
    "                    # move left n\n",
    "                    pixels[f'l: ({l_arrg[i-1-n]}, {l_arrg[i-n]}), b: ({b_arrg[j-1]}, {b_arrg[j]})'] = final_image[j-1, i-1-n]\n",
    "                    \n",
    "                    # move right n, up n\n",
    "                    pixels[f'l: ({l_arrg[i-1+n]}, {l_arrg[i+n]}), b: ({b_arrg[j-1+n]}, {b_arrg[j+n]})'] = final_image[j-1+n, i-1+n]\n",
    "                    \n",
    "                    # move left n, down n\n",
    "                    pixels[f'l: ({l_arrg[i-1-n]}, {l_arrg[i-n]}), b: ({b_arrg[j-1-n]}, {b_arrg[j-n]})'] = final_image[j-1-n, i-1-n]\n",
    "\n",
    "                    # move right n, down n\n",
    "                    pixels[f'l: ({l_arrg[i-1+n]}, {l_arrg[i+n]}), b: ({b_arrg[j-1-n]}, {b_arrg[j-n]})'] = final_image[j-1-n, i-1+n]\n",
    "                    \n",
    "                    # move left n, up n\n",
    "                    pixels[f'l: ({l_arrg[i-1-n]}, {l_arrg[i-n]}), b: ({b_arrg[j-1+n]}, {b_arrg[j+n]})'] = final_image[j-1+n, i-1-n]\n",
    "                \n",
    "    \n",
    "                return pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get flux in image without masking poor exposure\n",
    "#final_image = map_iterations[:,:, idx]\n",
    "\n",
    "# Get total sum with masking poor exposure\n",
    "map_iterations_nan_to_zero = np.nan_to_num(map_iterations_nan)\n",
    "final_image = np.roll(map_iterations_nan_to_zero[:, :, idx], axis=1, shift=0)\n",
    "\n",
    "pixels = get_pixel_flux(final_image, l=3, b=3, num_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = dict(sorted(pixels.items(), key=lambda item:item[1], reverse=True))  \n",
    "    \n",
    "for k, v in sort.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = list(pixels.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(fluxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max flux in a single pixel of the whole image\n",
    "max_flux = max(np.ravel(final_image*domega))\n",
    "print(max_flux)\n",
    "\n",
    "l_max_idx = np.where(final_image*domega == max_flux)[1][0]\n",
    "b_max_idx = np.where(final_image*domega == max_flux)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_max = l_arrg[l_max_idx]\n",
    "l_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_max = b_arrg[b_max_idx]\n",
    "b_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top 30 pixels with highest flux\n",
    "for i in range(30):\n",
    "    print(np.sort(np.ravel(final_image*domega))[::-1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COSIMain",
   "language": "python",
   "name": "cosimain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
